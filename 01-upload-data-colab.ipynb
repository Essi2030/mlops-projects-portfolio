{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "686e4f52",
   "metadata": {},
   "source": [
    "# üìò Upload Data to S3 ‚Äì Google Colab + AWS\n",
    "This notebook will connect your Colab environment to AWS and upload a sample churn dataset to Amazon S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac7d5d",
   "metadata": {},
   "source": [
    "## üîê Step 1: Set Your AWS Credentials\n",
    "_(Use IAM user credentials with S3 full access ‚Äì NEVER share them)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cea281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚õî IMPORTANT: Replace with your actual AWS credentials\n",
    "aws_access_key = 'YOUR_AWS_ACCESS_KEY_ID'\n",
    "aws_secret_key = 'YOUR_AWS_SECRET_ACCESS_KEY'\n",
    "region_name = 'us-east-1'  # or your preferred region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede533d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3 pandas scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import os\n",
    "\n",
    "# Set credentials as environment variables (used by boto3)\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = aws_access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = aws_secret_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40e0e1",
   "metadata": {},
   "source": [
    "## üìä Step 2: Load and Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc9700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load churn dataset from OpenML\n",
    "data = fetch_openml(\"telco-customer-churn\", version=1, as_frame=True)\n",
    "df = data.frame.dropna()\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"churn.csv\", index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f48753",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Step 3: Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268deb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to S3\n",
    "s3 = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "# Define bucket and upload\n",
    "bucket_name = 'your-sagemaker-bucket-name'  # üîÅ replace with your S3 bucket name\n",
    "s3_key = 'automl-churn/churn.csv'\n",
    "\n",
    "s3.upload_file('churn.csv', bucket_name, s3_key)\n",
    "print(f\"‚úÖ Uploaded to s3://{bucket_name}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62853a4d",
   "metadata": {},
   "source": [
    "üöÄ Done! Your dataset is now in S3 and ready for SageMaker Autopilot."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}